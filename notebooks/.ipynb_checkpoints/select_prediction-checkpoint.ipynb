{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bibliographic-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import re\n",
    "from itertools import zip_longest\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from rouge import Rouge\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from easse.sari import corpus_sari\n",
    "from razdel import tokenize\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from eli5 import explain_weights_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "miniature-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"./data\")\n",
    "\n",
    "WIKI_DIR = DATA_DIR / \"WikiSimple-translated\"\n",
    "PARAPHRASER_PATH = DATA_DIR / \"ParaPhraserPlus\" / \"ParaPhraserPlus.json\"\n",
    "\n",
    "DEV_PATH = DATA_DIR / \"dev_sents.csv\"\n",
    "TEST_PATH = DATA_DIR / \"public_test_only.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "varied-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ready-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_tokens(text):\n",
    "    tokens = re.sub(r\"[^\\w\\s]\", \"\", text).split()\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "familiar-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "elegant-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarities(model, tokenizer, input_texts, output_texts):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(input_texts, padding=True, truncation=True,\n",
    "                              max_length=MAX_LENGTH, return_tensors='pt').to(model.device)\n",
    "    encoded_output = tokenizer(output_texts, padding=True, truncation=True,\n",
    "                              max_length=MAX_LENGTH, return_tensors='pt').to(model.device)\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_emb_input = model(**encoded_input)\n",
    "        model_emb_output = model(**encoded_output)\n",
    "\n",
    "    # Perform pooling. In this case, mean pooling\n",
    "    input_embeddings = mean_pooling(model_emb_input, encoded_input['attention_mask']).cpu()\n",
    "    output_embeddings = mean_pooling(model_emb_output, encoded_output['attention_mask']).cpu()\n",
    "    similarity = cosine_similarity(input_embeddings, output_embeddings)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "original-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rougel(input_text, output_text):\n",
    "    \"\"\"\n",
    "    Returns rouge-l f-score\n",
    "    \"\"\"\n",
    "    rouge = Rouge()\n",
    "    scores = []\n",
    "    # try/except because of empty output or just dot (in dev_sents)\n",
    "    try:\n",
    "        score = rouge.get_scores(input_text, output_text)[0]\n",
    "        score = score[\"rouge-l\"][\"f\"]\n",
    "    except ValueError:  \n",
    "        score = 0.0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "diverse-portland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(120138, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")\n",
    "model = AutoModel.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-twenty",
   "metadata": {},
   "source": [
    "# Dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-concord",
   "metadata": {},
   "source": [
    "## Dev dataset metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "looking-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = pd.read_csv(DATA_DIR / \"prepared_data\" / \"dev_df_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "swedish-sailing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>cosine_sim</th>\n",
       "      <th>rouge_l</th>\n",
       "      <th>input_len</th>\n",
       "      <th>output_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14 декабря 1944 года рабочий посёлок Ички был ...</td>\n",
       "      <td>14 декабря 1944 года рабочий посёлок Ички пере...</td>\n",
       "      <td>0.920691</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960 году была выпущена модель 172A. Изменени...</td>\n",
       "      <td>В 1960 году вышла модель 172А. Отличие в хвост...</td>\n",
       "      <td>0.873007</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960 году была выпущена модель 172A. Изменени...</td>\n",
       "      <td>В выпущенной в 1960 году модель имела изменени...</td>\n",
       "      <td>0.846864</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960 году была выпущена модель 172A. Изменени...</td>\n",
       "      <td>Изменения: в хвосте и руле направления с обрат...</td>\n",
       "      <td>0.723221</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960 году была выпущена модель 172A. Изменени...</td>\n",
       "      <td>Модель 172А с другим хвостовым оперением,  кре...</td>\n",
       "      <td>0.905622</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>Язгуля́мский язы́к (самоназвание — Yuzdami zev...</td>\n",
       "      <td>Язгулямский язык - один из языков, на котором ...</td>\n",
       "      <td>0.920762</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>Язгуля́мский язы́к (самоназвание — Yuzdami zev...</td>\n",
       "      <td>Язгуля́мский язы́к — один из памирских языков ...</td>\n",
       "      <td>0.956768</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403</th>\n",
       "      <td>Японский космический аппарат Хаябуса успешно д...</td>\n",
       "      <td>Японский космический аппарат Хаябуса успешно д...</td>\n",
       "      <td>0.977265</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>Изображение соцветия подсолнечника на щите озн...</td>\n",
       "      <td>Соцветие подсолнечника - олицетворение сегодня...</td>\n",
       "      <td>0.777837</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3405</th>\n",
       "      <td>Изображение соцветия подсолнечника на щите озн...</td>\n",
       "      <td>Подсолнечник, который изображён на щите, симво...</td>\n",
       "      <td>0.936641</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3406 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  input  \\\n",
       "0     14 декабря 1944 года рабочий посёлок Ички был ...   \n",
       "1      1960 году была выпущена модель 172A. Изменени...   \n",
       "2      1960 году была выпущена модель 172A. Изменени...   \n",
       "3      1960 году была выпущена модель 172A. Изменени...   \n",
       "4      1960 году была выпущена модель 172A. Изменени...   \n",
       "...                                                 ...   \n",
       "3401  Язгуля́мский язы́к (самоназвание — Yuzdami zev...   \n",
       "3402  Язгуля́мский язы́к (самоназвание — Yuzdami zev...   \n",
       "3403  Японский космический аппарат Хаябуса успешно д...   \n",
       "3404  Изображение соцветия подсолнечника на щите озн...   \n",
       "3405  Изображение соцветия подсолнечника на щите озн...   \n",
       "\n",
       "                                                 output  cosine_sim   rouge_l  \\\n",
       "0     14 декабря 1944 года рабочий посёлок Ички пере...    0.920691  0.642857   \n",
       "1     В 1960 году вышла модель 172А. Отличие в хвост...    0.873007  0.352941   \n",
       "2     В выпущенной в 1960 году модель имела изменени...    0.846864  0.312500   \n",
       "3     Изменения: в хвосте и руле направления с обрат...    0.723221  0.606061   \n",
       "4     Модель 172А с другим хвостовым оперением,  кре...    0.905622  0.324324   \n",
       "...                                                 ...         ...       ...   \n",
       "3401  Язгулямский язык - один из языков, на котором ...    0.920762  0.388889   \n",
       "3402  Язгуля́мский язы́к — один из памирских языков ...    0.956768  0.529412   \n",
       "3403  Японский космический аппарат Хаябуса успешно д...    0.977265  0.896552   \n",
       "3404  Соцветие подсолнечника - олицетворение сегодня...    0.777837  0.210526   \n",
       "3405  Подсолнечник, который изображён на щите, симво...    0.936641  0.333333   \n",
       "\n",
       "      input_len  output_len  \n",
       "0            20          10  \n",
       "1            20          17  \n",
       "2            20          14  \n",
       "3            20          14  \n",
       "4            20          19  \n",
       "...         ...         ...  \n",
       "3401         18          17  \n",
       "3402         18          15  \n",
       "3403         15          14  \n",
       "3404         13           5  \n",
       "3405         13          11  \n",
       "\n",
       "[3406 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bulgarian-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df_grouped = dev_df.groupby(\"input\").agg(\n",
    "    {\"output\": list, \"cosine_sim\": list, \"rouge_l\": list, \"input_len\": max, \"output_len\": list}\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "micro-rover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>cosine_sim</th>\n",
       "      <th>rouge_l</th>\n",
       "      <th>input_len</th>\n",
       "      <th>output_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960 году была выпущена модель 172A. Изменени...</td>\n",
       "      <td>[В 1960 году вышла модель 172А. Отличие в хвос...</td>\n",
       "      <td>[0.8730071783065796, 0.8468641042709351, 0.723...</td>\n",
       "      <td>[0.3529411715397924, 0.3124999951757813, 0.606...</td>\n",
       "      <td>20</td>\n",
       "      <td>[17, 14, 14, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14 декабря 1944 года рабочий посёлок Ички был ...</td>\n",
       "      <td>[14 декабря 1944 года рабочий посёлок Ички пер...</td>\n",
       "      <td>[0.9206905961036682]</td>\n",
       "      <td>[0.6428571382653062]</td>\n",
       "      <td>20</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26 августа 2014 года Болдок принял участие в п...</td>\n",
       "      <td>[26 августа 2014 года Болдок выиграл футбольны...</td>\n",
       "      <td>[0.8274444937705994, 0.9261506199836732]</td>\n",
       "      <td>[0.5777777729777778, 0.6222222174222223]</td>\n",
       "      <td>28</td>\n",
       "      <td>[18, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armory — клиент с различными функциями для пов...</td>\n",
       "      <td>[Armory - программа с различными функциями для...</td>\n",
       "      <td>[0.924230694770813]</td>\n",
       "      <td>[0.5454545404648761]</td>\n",
       "      <td>20</td>\n",
       "      <td>[23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Concert for Diana (рус. Концерт для Дианы) — к...</td>\n",
       "      <td>[Concert for Diana - это концерт, посвящённый ...</td>\n",
       "      <td>[0.8712961673736572, 0.8228520154953003, 0.875...</td>\n",
       "      <td>[0.3703703655418381, 0.319999995392, 0.3999999...</td>\n",
       "      <td>15</td>\n",
       "      <td>[10, 9, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Эффективность азитромицина при лечении инфекци...</td>\n",
       "      <td>[Азитромицин показал свою эффективность в лече...</td>\n",
       "      <td>[0.9227253198623656, 0.6798684597015381, 0.837...</td>\n",
       "      <td>[0.5714285664540818, 0.1052631545706372, 0.357...</td>\n",
       "      <td>15</td>\n",
       "      <td>[13, 4, 13, 8, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Юг и среднюю часть республики занимают горы и ...</td>\n",
       "      <td>[Часть республики занимают горы, а часть низме...</td>\n",
       "      <td>[0.7854164242744446, 0.9339486956596376]</td>\n",
       "      <td>[0.2727272683884298, 0.3999999952]</td>\n",
       "      <td>16</td>\n",
       "      <td>[7, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Юго-Восточное побережье — Феодосийский и Судак...</td>\n",
       "      <td>[Весь Крым находится под охраной государства.,...</td>\n",
       "      <td>[0.6608866453170776, 0.8181402087211609, 0.882...</td>\n",
       "      <td>[0.2857142816326531, 0.3571428521683673, 0.479...</td>\n",
       "      <td>14</td>\n",
       "      <td>[6, 13, 10, 12, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Язгуля́мский язы́к (самоназвание — Yuzdami zev...</td>\n",
       "      <td>[Язгулямский язык - один из языков, на котором...</td>\n",
       "      <td>[0.9207618236541748, 0.9567684531211852]</td>\n",
       "      <td>[0.388888883904321, 0.5294117597750866]</td>\n",
       "      <td>18</td>\n",
       "      <td>[17, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Японский космический аппарат Хаябуса успешно д...</td>\n",
       "      <td>[Японский космический аппарат Хаябуса успешно ...</td>\n",
       "      <td>[0.9772647023200988]</td>\n",
       "      <td>[0.8965517191438764]</td>\n",
       "      <td>15</td>\n",
       "      <td>[14]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input  \\\n",
       "0     1960 году была выпущена модель 172A. Изменени...   \n",
       "1    14 декабря 1944 года рабочий посёлок Ички был ...   \n",
       "2    26 августа 2014 года Болдок принял участие в п...   \n",
       "3    Armory — клиент с различными функциями для пов...   \n",
       "4    Concert for Diana (рус. Концерт для Дианы) — к...   \n",
       "..                                                 ...   \n",
       "995  Эффективность азитромицина при лечении инфекци...   \n",
       "996  Юг и среднюю часть республики занимают горы и ...   \n",
       "997  Юго-Восточное побережье — Феодосийский и Судак...   \n",
       "998  Язгуля́мский язы́к (самоназвание — Yuzdami zev...   \n",
       "999  Японский космический аппарат Хаябуса успешно д...   \n",
       "\n",
       "                                                output  \\\n",
       "0    [В 1960 году вышла модель 172А. Отличие в хвос...   \n",
       "1    [14 декабря 1944 года рабочий посёлок Ички пер...   \n",
       "2    [26 августа 2014 года Болдок выиграл футбольны...   \n",
       "3    [Armory - программа с различными функциями для...   \n",
       "4    [Concert for Diana - это концерт, посвящённый ...   \n",
       "..                                                 ...   \n",
       "995  [Азитромицин показал свою эффективность в лече...   \n",
       "996  [Часть республики занимают горы, а часть низме...   \n",
       "997  [Весь Крым находится под охраной государства.,...   \n",
       "998  [Язгулямский язык - один из языков, на котором...   \n",
       "999  [Японский космический аппарат Хаябуса успешно ...   \n",
       "\n",
       "                                            cosine_sim  \\\n",
       "0    [0.8730071783065796, 0.8468641042709351, 0.723...   \n",
       "1                                 [0.9206905961036682]   \n",
       "2             [0.8274444937705994, 0.9261506199836732]   \n",
       "3                                  [0.924230694770813]   \n",
       "4    [0.8712961673736572, 0.8228520154953003, 0.875...   \n",
       "..                                                 ...   \n",
       "995  [0.9227253198623656, 0.6798684597015381, 0.837...   \n",
       "996           [0.7854164242744446, 0.9339486956596376]   \n",
       "997  [0.6608866453170776, 0.8181402087211609, 0.882...   \n",
       "998           [0.9207618236541748, 0.9567684531211852]   \n",
       "999                               [0.9772647023200988]   \n",
       "\n",
       "                                               rouge_l  input_len  \\\n",
       "0    [0.3529411715397924, 0.3124999951757813, 0.606...         20   \n",
       "1                                 [0.6428571382653062]         20   \n",
       "2             [0.5777777729777778, 0.6222222174222223]         28   \n",
       "3                                 [0.5454545404648761]         20   \n",
       "4    [0.3703703655418381, 0.319999995392, 0.3999999...         15   \n",
       "..                                                 ...        ...   \n",
       "995  [0.5714285664540818, 0.1052631545706372, 0.357...         15   \n",
       "996                 [0.2727272683884298, 0.3999999952]         16   \n",
       "997  [0.2857142816326531, 0.3571428521683673, 0.479...         14   \n",
       "998            [0.388888883904321, 0.5294117597750866]         18   \n",
       "999                               [0.8965517191438764]         15   \n",
       "\n",
       "             output_len  \n",
       "0      [17, 14, 14, 19]  \n",
       "1                  [10]  \n",
       "2              [18, 18]  \n",
       "3                  [23]  \n",
       "4            [10, 9, 8]  \n",
       "..                  ...  \n",
       "995  [13, 4, 13, 8, 13]  \n",
       "996              [7, 9]  \n",
       "997  [6, 13, 10, 12, 7]  \n",
       "998            [17, 15]  \n",
       "999                [14]  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-contemporary",
   "metadata": {},
   "source": [
    "## Predictions for dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "centered-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.read_csv(\"submissions/dev_1_ep3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "macro-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame({\"pred\": preds.values.reshape(-1, 1).ravel()})\n",
    "preds_df[\"input\"] = np.array([[i] * 5 for i in dev_df_grouped[\"input\"]]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "reserved-entry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 20s, sys: 298 ms, total: 2min 20s\n",
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds_df[\"cosine_sim\"] = preds_df.apply(\n",
    "    lambda x: get_similarities(model, tokenizer, x[\"pred\"], x[\"input\"]), axis=1\n",
    ")\n",
    "preds_df[\"cosine_sim\"] = preds_df[\"cosine_sim\"].apply(lambda x: x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "selected-hearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.57 s, sys: 7.98 ms, total: 1.57 s\n",
      "Wall time: 1.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds_df[\"rouge_l\"] = preds_df.apply(lambda x: get_rougel(x[\"pred\"], x[\"input\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "auburn-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"ref\"] = [l for sublist in dev_df_grouped[\"output\"].apply(lambda x: [x] * 5).tolist() for l in sublist]\n",
    "preds_df[\"ref\"] = preds_df[\"ref\"].apply(lambda x: [[i] for i in x])\n",
    "\n",
    "preds_df[\"pred_len\"] = preds_df[\"pred\"].apply(lambda x: len(get_word_tokens(x)))\n",
    "preds_df[\"input_len\"] = preds_df[\"input\"].apply(lambda x: len(get_word_tokens(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "seventh-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"sari\"] = preds_df.apply(\n",
    "    lambda x: corpus_sari(\n",
    "        orig_sents=[x[\"input\"]],\n",
    "        sys_sents=[x[\"pred\"]],\n",
    "        refs_sents=x[\"ref\"],\n",
    "    ), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "incoming-compression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>input</th>\n",
       "      <th>cosine_sim</th>\n",
       "      <th>rouge_l</th>\n",
       "      <th>ref</th>\n",
       "      <th>pred_len</th>\n",
       "      <th>input_len</th>\n",
       "      <th>sari</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960 г. - модель 172A была изменена с хвостово...</td>\n",
       "      <td>1960 году была выпущена модель 172A. Изменени...</td>\n",
       "      <td>0.826491</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>[[В 1960 году вышла модель 172А. Отличие в хво...</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>32.689777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хвостовое оперение и рулевое управление с обра...</td>\n",
       "      <td>1960 году была выпущена модель 172A. Изменени...</td>\n",
       "      <td>0.785438</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>[[В 1960 году вышла модель 172А. Отличие в хво...</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>38.717239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960 г. - модель 172A была изменена на хвостов...</td>\n",
       "      <td>1960 году была выпущена модель 172A. Изменени...</td>\n",
       "      <td>0.892796</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[[В 1960 году вышла модель 172А. Отличие в хво...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>31.435584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Смены. Изменения: хвостовое оперение и рулевое...</td>\n",
       "      <td>1960 году была выпущена модель 172A. Изменени...</td>\n",
       "      <td>0.766883</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[[В 1960 году вышла модель 172А. Отличие в хво...</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>32.542526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Смена конструкции: хвостовое оперение и рулево...</td>\n",
       "      <td>1960 году была выпущена модель 172A. Изменени...</td>\n",
       "      <td>0.761799</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>[[В 1960 году вышла модель 172А. Отличие в хво...</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>36.499031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>\"Японский космический аппарат Хаябуса успешно ...</td>\n",
       "      <td>Японский космический аппарат Хаябуса успешно д...</td>\n",
       "      <td>0.922836</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>[[Японский космический аппарат Хаябуса успешно...</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>26.061508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>\"Японский космический аппарат Хаябуса успешно ...</td>\n",
       "      <td>Японский космический аппарат Хаябуса успешно д...</td>\n",
       "      <td>0.928726</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>[[Японский космический аппарат Хаябуса успешно...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>54.897741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>\"Японский космический аппарат Xаябуса успешно ...</td>\n",
       "      <td>Японский космический аппарат Хаябуса успешно д...</td>\n",
       "      <td>0.909516</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>[[Японский космический аппарат Хаябуса успешно...</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>20.000542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>\"Японский космический корабль Xаябуса успешно ...</td>\n",
       "      <td>Японский космический аппарат Хаябуса успешно д...</td>\n",
       "      <td>0.924177</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[[Японский космический аппарат Хаябуса успешно...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>17.433166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>\"Японский космический корабль \"Хаябуса\" успешн...</td>\n",
       "      <td>Японский космический аппарат Хаябуса успешно д...</td>\n",
       "      <td>0.912012</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>[[Японский космический аппарат Хаябуса успешно...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>22.703637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pred  \\\n",
       "0     1960 г. - модель 172A была изменена с хвостово...   \n",
       "1     Хвостовое оперение и рулевое управление с обра...   \n",
       "2     1960 г. - модель 172A была изменена на хвостов...   \n",
       "3     Смены. Изменения: хвостовое оперение и рулевое...   \n",
       "4     Смена конструкции: хвостовое оперение и рулево...   \n",
       "...                                                 ...   \n",
       "4995  \"Японский космический аппарат Хаябуса успешно ...   \n",
       "4996  \"Японский космический аппарат Хаябуса успешно ...   \n",
       "4997  \"Японский космический аппарат Xаябуса успешно ...   \n",
       "4998  \"Японский космический корабль Xаябуса успешно ...   \n",
       "4999  \"Японский космический корабль \"Хаябуса\" успешн...   \n",
       "\n",
       "                                                  input  cosine_sim   rouge_l  \\\n",
       "0      1960 году была выпущена модель 172A. Изменени...    0.826491  0.270270   \n",
       "1      1960 году была выпущена модель 172A. Изменени...    0.785438  0.580645   \n",
       "2      1960 году была выпущена модель 172A. Изменени...    0.892796  0.666667   \n",
       "3      1960 году была выпущена модель 172A. Изменени...    0.766883  0.666667   \n",
       "4      1960 году была выпущена модель 172A. Изменени...    0.761799  0.606061   \n",
       "...                                                 ...         ...       ...   \n",
       "4995  Японский космический аппарат Хаябуса успешно д...    0.922836  0.812500   \n",
       "4996  Японский космический аппарат Хаябуса успешно д...    0.928726  0.551724   \n",
       "4997  Японский космический аппарат Хаябуса успешно д...    0.909516  0.774194   \n",
       "4998  Японский космический аппарат Хаябуса успешно д...    0.924177  0.666667   \n",
       "4999  Японский космический аппарат Хаябуса успешно д...    0.912012  0.800000   \n",
       "\n",
       "                                                    ref  pred_len  input_len  \\\n",
       "0     [[В 1960 году вышла модель 172А. Отличие в хво...        17         20   \n",
       "1     [[В 1960 году вышла модель 172А. Отличие в хво...        13         20   \n",
       "2     [[В 1960 году вышла модель 172А. Отличие в хво...        20         20   \n",
       "3     [[В 1960 году вышла модель 172А. Отличие в хво...        15         20   \n",
       "4     [[В 1960 году вышла модель 172А. Отличие в хво...        15         20   \n",
       "...                                                 ...       ...        ...   \n",
       "4995  [[Японский космический аппарат Хаябуса успешно...        16         15   \n",
       "4996  [[Японский космический аппарат Хаябуса успешно...        14         15   \n",
       "4997  [[Японский космический аппарат Хаябуса успешно...        16         15   \n",
       "4998  [[Японский космический аппарат Хаябуса успешно...        15         15   \n",
       "4999  [[Японский космический аппарат Хаябуса успешно...        15         15   \n",
       "\n",
       "           sari  \n",
       "0     32.689777  \n",
       "1     38.717239  \n",
       "2     31.435584  \n",
       "3     32.542526  \n",
       "4     36.499031  \n",
       "...         ...  \n",
       "4995  26.061508  \n",
       "4996  54.897741  \n",
       "4997  20.000542  \n",
       "4998  17.433166  \n",
       "4999  22.703637  \n",
       "\n",
       "[5000 rows x 8 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-costa",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-harmony",
   "metadata": {},
   "source": [
    "#### Fit part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "limited-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_jobs=-1, random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "renewable-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preds_df[[\"cosine_sim\", \"rouge_l\", \"input_len\", \"pred_len\"]][:4000]\n",
    "y_train = preds_df[\"sari\"][:4000]\n",
    "X_test = preds_df[[\"cosine_sim\", \"rouge_l\", \"input_len\", \"pred_len\"]][4000:]\n",
    "y_test = preds_df[\"sari\"][4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "pressing-parking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1, random_state=19)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bigger-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"sari_pred\"] = rf.predict(preds_df[[\"cosine_sim\", \"rouge_l\", \"input_len\", \"pred_len\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "tired-framing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>input</th>\n",
       "      <th>cosine_sim</th>\n",
       "      <th>rouge_l</th>\n",
       "      <th>ref</th>\n",
       "      <th>pred_len</th>\n",
       "      <th>input_len</th>\n",
       "      <th>sari</th>\n",
       "      <th>sari_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960 г. - модель 172A была изменена с хвостово...</td>\n",
       "      <td>1960 году была выпущена модель 172A. Изменени...</td>\n",
       "      <td>0.826491</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>[[В 1960 году вышла модель 172А. Отличие в хво...</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>32.689777</td>\n",
       "      <td>35.020007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хвостовое оперение и рулевое управление с обра...</td>\n",
       "      <td>1960 году была выпущена модель 172A. Изменени...</td>\n",
       "      <td>0.785438</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>[[В 1960 году вышла модель 172А. Отличие в хво...</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>38.717239</td>\n",
       "      <td>39.297168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960 г. - модель 172A была изменена на хвостов...</td>\n",
       "      <td>1960 году была выпущена модель 172A. Изменени...</td>\n",
       "      <td>0.892796</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[[В 1960 году вышла модель 172А. Отличие в хво...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>31.435584</td>\n",
       "      <td>29.140264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Смены. Изменения: хвостовое оперение и рулевое...</td>\n",
       "      <td>1960 году была выпущена модель 172A. Изменени...</td>\n",
       "      <td>0.766883</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[[В 1960 году вышла модель 172А. Отличие в хво...</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>32.542526</td>\n",
       "      <td>33.516263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Смена конструкции: хвостовое оперение и рулево...</td>\n",
       "      <td>1960 году была выпущена модель 172A. Изменени...</td>\n",
       "      <td>0.761799</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>[[В 1960 году вышла модель 172А. Отличие в хво...</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>36.499031</td>\n",
       "      <td>35.040157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>\"Японский космический аппарат Хаябуса успешно ...</td>\n",
       "      <td>Японский космический аппарат Хаябуса успешно д...</td>\n",
       "      <td>0.922836</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>[[Японский космический аппарат Хаябуса успешно...</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>26.061508</td>\n",
       "      <td>23.401204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>\"Японский космический аппарат Хаябуса успешно ...</td>\n",
       "      <td>Японский космический аппарат Хаябуса успешно д...</td>\n",
       "      <td>0.928726</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>[[Японский космический аппарат Хаябуса успешно...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>54.897741</td>\n",
       "      <td>38.849847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>\"Японский космический аппарат Xаябуса успешно ...</td>\n",
       "      <td>Японский космический аппарат Хаябуса успешно д...</td>\n",
       "      <td>0.909516</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>[[Японский космический аппарат Хаябуса успешно...</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>20.000542</td>\n",
       "      <td>22.312628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>\"Японский космический корабль Xаябуса успешно ...</td>\n",
       "      <td>Японский космический аппарат Хаябуса успешно д...</td>\n",
       "      <td>0.924177</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[[Японский космический аппарат Хаябуса успешно...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>17.433166</td>\n",
       "      <td>31.748565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>\"Японский космический корабль \"Хаябуса\" успешн...</td>\n",
       "      <td>Японский космический аппарат Хаябуса успешно д...</td>\n",
       "      <td>0.912012</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>[[Японский космический аппарат Хаябуса успешно...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>22.703637</td>\n",
       "      <td>22.826718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pred  \\\n",
       "0     1960 г. - модель 172A была изменена с хвостово...   \n",
       "1     Хвостовое оперение и рулевое управление с обра...   \n",
       "2     1960 г. - модель 172A была изменена на хвостов...   \n",
       "3     Смены. Изменения: хвостовое оперение и рулевое...   \n",
       "4     Смена конструкции: хвостовое оперение и рулево...   \n",
       "...                                                 ...   \n",
       "4995  \"Японский космический аппарат Хаябуса успешно ...   \n",
       "4996  \"Японский космический аппарат Хаябуса успешно ...   \n",
       "4997  \"Японский космический аппарат Xаябуса успешно ...   \n",
       "4998  \"Японский космический корабль Xаябуса успешно ...   \n",
       "4999  \"Японский космический корабль \"Хаябуса\" успешн...   \n",
       "\n",
       "                                                  input  cosine_sim   rouge_l  \\\n",
       "0      1960 году была выпущена модель 172A. Изменени...    0.826491  0.270270   \n",
       "1      1960 году была выпущена модель 172A. Изменени...    0.785438  0.580645   \n",
       "2      1960 году была выпущена модель 172A. Изменени...    0.892796  0.666667   \n",
       "3      1960 году была выпущена модель 172A. Изменени...    0.766883  0.666667   \n",
       "4      1960 году была выпущена модель 172A. Изменени...    0.761799  0.606061   \n",
       "...                                                 ...         ...       ...   \n",
       "4995  Японский космический аппарат Хаябуса успешно д...    0.922836  0.812500   \n",
       "4996  Японский космический аппарат Хаябуса успешно д...    0.928726  0.551724   \n",
       "4997  Японский космический аппарат Хаябуса успешно д...    0.909516  0.774194   \n",
       "4998  Японский космический аппарат Хаябуса успешно д...    0.924177  0.666667   \n",
       "4999  Японский космический аппарат Хаябуса успешно д...    0.912012  0.800000   \n",
       "\n",
       "                                                    ref  pred_len  input_len  \\\n",
       "0     [[В 1960 году вышла модель 172А. Отличие в хво...        17         20   \n",
       "1     [[В 1960 году вышла модель 172А. Отличие в хво...        13         20   \n",
       "2     [[В 1960 году вышла модель 172А. Отличие в хво...        20         20   \n",
       "3     [[В 1960 году вышла модель 172А. Отличие в хво...        15         20   \n",
       "4     [[В 1960 году вышла модель 172А. Отличие в хво...        15         20   \n",
       "...                                                 ...       ...        ...   \n",
       "4995  [[Японский космический аппарат Хаябуса успешно...        16         15   \n",
       "4996  [[Японский космический аппарат Хаябуса успешно...        14         15   \n",
       "4997  [[Японский космический аппарат Хаябуса успешно...        16         15   \n",
       "4998  [[Японский космический аппарат Хаябуса успешно...        15         15   \n",
       "4999  [[Японский космический аппарат Хаябуса успешно...        15         15   \n",
       "\n",
       "           sari  sari_pred  \n",
       "0     32.689777  35.020007  \n",
       "1     38.717239  39.297168  \n",
       "2     31.435584  29.140264  \n",
       "3     32.542526  33.516263  \n",
       "4     36.499031  35.040157  \n",
       "...         ...        ...  \n",
       "4995  26.061508  23.401204  \n",
       "4996  54.897741  38.849847  \n",
       "4997  20.000542  22.312628  \n",
       "4998  17.433166  31.748565  \n",
       "4999  22.703637  22.826718  \n",
       "\n",
       "[5000 rows x 9 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "opening-university",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>input</th>\n",
       "      <th>cosine_sim</th>\n",
       "      <th>rouge_l</th>\n",
       "      <th>ref</th>\n",
       "      <th>pred_len</th>\n",
       "      <th>input_len</th>\n",
       "      <th>sari</th>\n",
       "      <th>sari_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>Хотя мечте Петра не суждено было сбыться, имен...</td>\n",
       "      <td>Хотя мечте Петра не суждено было сбыться, имен...</td>\n",
       "      <td>0.974633</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>[[Петр начал стройку, увидев похожее за рубежо...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>22.163183</td>\n",
       "      <td>26.045381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4774</th>\n",
       "      <td>\"Хотя мечте Петра не суждено было сбыться, име...</td>\n",
       "      <td>Хотя мечте Петра не суждено было сбыться, имен...</td>\n",
       "      <td>0.911609</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>[[Петр начал стройку, увидев похожее за рубежо...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>22.163183</td>\n",
       "      <td>30.573813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>Хотя мечте Петра не суждено было сбыться, имен...</td>\n",
       "      <td>Хотя мечте Петра не суждено было сбыться, имен...</td>\n",
       "      <td>0.861299</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>[[Петр начал стройку, увидев похожее за рубежо...</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>23.967350</td>\n",
       "      <td>32.778133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>Хотя мечте Петра не суждено было сбыться, имен...</td>\n",
       "      <td>Хотя мечте Петра не суждено было сбыться, имен...</td>\n",
       "      <td>0.989460</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>[[Петр начал стройку, увидев похожее за рубежо...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>24.423720</td>\n",
       "      <td>28.070229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>Хотя мечте Петра не суждено было сбыться, имен...</td>\n",
       "      <td>Хотя мечте Петра не суждено было сбыться, имен...</td>\n",
       "      <td>0.989460</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>[[Петр начал стройку, увидев похожее за рубежо...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>24.423720</td>\n",
       "      <td>28.070229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pred  \\\n",
       "4771  Хотя мечте Петра не суждено было сбыться, имен...   \n",
       "4774  \"Хотя мечте Петра не суждено было сбыться, име...   \n",
       "4773  Хотя мечте Петра не суждено было сбыться, имен...   \n",
       "4770  Хотя мечте Петра не суждено было сбыться, имен...   \n",
       "4772  Хотя мечте Петра не суждено было сбыться, имен...   \n",
       "\n",
       "                                                  input  cosine_sim   rouge_l  \\\n",
       "4771  Хотя мечте Петра не суждено было сбыться, имен...    0.974633  0.827586   \n",
       "4774  Хотя мечте Петра не суждено было сбыться, имен...    0.911609  0.733333   \n",
       "4773  Хотя мечте Петра не суждено было сбыться, имен...    0.861299  0.642857   \n",
       "4770  Хотя мечте Петра не суждено было сбыться, имен...    0.989460  0.800000   \n",
       "4772  Хотя мечте Петра не суждено было сбыться, имен...    0.989460  0.800000   \n",
       "\n",
       "                                                    ref  pred_len  input_len  \\\n",
       "4771  [[Петр начал стройку, увидев похожее за рубежо...        14         15   \n",
       "4774  [[Петр начал стройку, увидев похожее за рубежо...        14         15   \n",
       "4773  [[Петр начал стройку, увидев похожее за рубежо...        13         15   \n",
       "4770  [[Петр начал стройку, увидев похожее за рубежо...        15         15   \n",
       "4772  [[Петр начал стройку, увидев похожее за рубежо...        15         15   \n",
       "\n",
       "           sari  sari_pred  \n",
       "4771  22.163183  26.045381  \n",
       "4774  22.163183  30.573813  \n",
       "4773  23.967350  32.778133  \n",
       "4770  24.423720  28.070229  \n",
       "4772  24.423720  28.070229  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.random.choice(np.arange(800, 1001))\n",
    "\n",
    "preds_df.sort_values([\"input\", \"sari\"])[i*5:i*5+5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-jacob",
   "metadata": {},
   "source": [
    "#### Fit whole dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "basic-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_jobs=-1, random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "compound-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preds_df[[\"cosine_sim\", \"rouge_l\", \"input_len\", \"pred_len\"]]\n",
    "y_train = preds_df[\"sari\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "opposite-input",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1, random_state=19)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "pleasant-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"sari_pred\"] = rf.predict(preds_df[[\"cosine_sim\", \"rouge_l\", \"input_len\", \"pred_len\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "neural-marketing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>input</th>\n",
       "      <th>cosine_sim</th>\n",
       "      <th>rouge_l</th>\n",
       "      <th>ref</th>\n",
       "      <th>pred_len</th>\n",
       "      <th>input_len</th>\n",
       "      <th>sari</th>\n",
       "      <th>sari_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4479</th>\n",
       "      <td>\"Таким образом, если, например, превращенная и...</td>\n",
       "      <td>Таким образом, если, например, превращённая из...</td>\n",
       "      <td>0.922345</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>[[Если пешка угрожает королю, то король сразу ...</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>23.209703</td>\n",
       "      <td>26.214509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>Это означает, что если, например, превращенная...</td>\n",
       "      <td>Таким образом, если, например, превращённая из...</td>\n",
       "      <td>0.893138</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>[[Если пешка угрожает королю, то король сразу ...</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>30.103601</td>\n",
       "      <td>31.329087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4477</th>\n",
       "      <td>Если, например, превращенная из пешки фигура у...</td>\n",
       "      <td>Таким образом, если, например, превращённая из...</td>\n",
       "      <td>0.915695</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>[[Если пешка угрожает королю, то король сразу ...</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>31.046662</td>\n",
       "      <td>30.026323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>Верно также то, что, если этот король находитс...</td>\n",
       "      <td>Таким образом, если, например, превращённая из...</td>\n",
       "      <td>0.783451</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>[[Если пешка угрожает королю, то король сразу ...</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>35.240109</td>\n",
       "      <td>34.897839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4476</th>\n",
       "      <td>Если фигура противника стоит на последней гори...</td>\n",
       "      <td>Таким образом, если, например, превращённая из...</td>\n",
       "      <td>0.856502</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>[[Если пешка угрожает королю, то король сразу ...</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>43.466395</td>\n",
       "      <td>40.742714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pred  \\\n",
       "4479  \"Таким образом, если, например, превращенная и...   \n",
       "4475  Это означает, что если, например, превращенная...   \n",
       "4477  Если, например, превращенная из пешки фигура у...   \n",
       "4478  Верно также то, что, если этот король находитс...   \n",
       "4476  Если фигура противника стоит на последней гори...   \n",
       "\n",
       "                                                  input  cosine_sim   rouge_l  \\\n",
       "4479  Таким образом, если, например, превращённая из...    0.922345  0.807018   \n",
       "4475  Таким образом, если, например, превращённая из...    0.893138  0.701754   \n",
       "4477  Таким образом, если, например, превращённая из...    0.915695  0.754717   \n",
       "4478  Таким образом, если, например, превращённая из...    0.783451  0.528302   \n",
       "4476  Таким образом, если, например, превращённая из...    0.856502  0.272727   \n",
       "\n",
       "                                                    ref  pred_len  input_len  \\\n",
       "4479  [[Если пешка угрожает королю, то король сразу ...        26         31   \n",
       "4475  [[Если пешка угрожает королю, то король сразу ...        26         31   \n",
       "4477  [[Если пешка угрожает королю, то король сразу ...        22         31   \n",
       "4478  [[Если пешка угрожает королю, то король сразу ...        27         31   \n",
       "4476  [[Если пешка угрожает королю, то король сразу ...        13         31   \n",
       "\n",
       "           sari  sari_pred  \n",
       "4479  23.209703  26.214509  \n",
       "4475  30.103601  31.329087  \n",
       "4477  31.046662  30.026323  \n",
       "4478  35.240109  34.897839  \n",
       "4476  43.466395  40.742714  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.random.choice(1000)\n",
    "\n",
    "preds_df.sort_values([\"input\", \"sari\"])[i*5:i*5+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-charleston",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "curious-cambridge",
   "metadata": {},
   "source": [
    "### SARI for whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "encouraging-nylon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.85631583959559"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max sari\n",
    "corpus_sari(\n",
    "    orig_sents=dev_df_grouped[\"input\"].tolist(),\n",
    "    sys_sents=preds_df.sort_values([\"input\", \"sari\"], ascending=[True, False])[\"pred\"][::5].tolist(), \n",
    "    refs_sents=list(zip_longest(*dev_df_grouped[\"output\"].tolist(), fillvalue=\"\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "characteristic-shadow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.2390345048515"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min length\n",
    "corpus_sari(\n",
    "    orig_sents=dev_df_grouped[\"input\"].tolist(),\n",
    "    sys_sents=preds_df.sort_values([\"input\", \"pred_len\"], ascending=[True, True])[\"pred\"][::5].tolist(), \n",
    "    refs_sents=list(zip_longest(*dev_df_grouped[\"output\"].tolist(), fillvalue=\"\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "technological-homeless",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.24462192733768"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min cosine similarity\n",
    "corpus_sari(\n",
    "    orig_sents=dev_df_grouped[\"input\"].tolist(),\n",
    "    sys_sents=preds_df.sort_values([\"input\", \"cosine_sim\"], ascending=[True, True])[\"pred\"][::5].tolist(), \n",
    "    refs_sents=list(zip_longest(*dev_df_grouped[\"output\"].tolist(), fillvalue=\"\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "normal-cable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.65483087479079"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min rouge-l\n",
    "corpus_sari(\n",
    "    orig_sents=dev_df_grouped[\"input\"].tolist(),\n",
    "    sys_sents=preds_df.sort_values([\"input\", \"rouge_l\"], ascending=[True, True])[\"pred\"][::5].tolist(), \n",
    "    refs_sents=list(zip_longest(*dev_df_grouped[\"output\"].tolist(), fillvalue=\"\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-ballet",
   "metadata": {},
   "source": [
    "# Predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "seven-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEST_PATH) as f:\n",
    "    test_input = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "popular-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = pd.read_csv(\"submissions/3_sim_ep3_bs8_5.csv\")\n",
    "\n",
    "pred_test = pd.DataFrame({\"pred\": pred_test.values.reshape(-1, 1).ravel()})\n",
    "pred_test[\"input\"] = np.array([[i] * 5 for i in test_input]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "enclosed-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test[\"pred_len\"] = pred_test[\"pred\"].apply(lambda x: len(get_word_tokens(x)))\n",
    "pred_test[\"cosine_sim\"] = pred_test.apply(lambda x: get_similarities(model, tokenizer, x[\"pred\"], x[\"input\"]),\n",
    "                                    axis=1)\n",
    "pred_test[\"cosine_sim\"] = pred_test[\"cosine_sim\"].apply(lambda x: x[0][0])\n",
    "pred_test[\"rouge_l\"] = pred_test.apply(lambda x: get_rougel(x[\"pred\"], x[\"input\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-couple",
   "metadata": {},
   "source": [
    "## Predict by min of some metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "supposed-music",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       Архиепископ Тихон снова удостоил его рукополож...\n",
       "5       22 марта 1951 года советское правительство наг...\n",
       "12      В 1821 году представители испанской короны и И...\n",
       "18      Феодор был назначен наместником Петропавловско...\n",
       "21      Он был выпущен для использования в качестве во...\n",
       "                              ...                        \n",
       "4975    В физике это называется гравитационным взаимод...\n",
       "4982    Mac OS X - это популярная операционная система...\n",
       "4988    Это означало, что бренд использовал шоковую ре...\n",
       "4994    Этот жанр стал очень популярным во времена «но...\n",
       "4997    В Маньчжурии армия Красной Армии, которая позж...\n",
       "Name: pred, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.sort_values([\"input\", \"rouge_l\"], ascending=True)[\"pred\"][::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cultural-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.sort_values([\"input\", \"rouge_l\"], ascending=True)[\"pred\"][::5].to_csv(\n",
    "    \"submissions/08_sim_bs8_ep3_min_rougel/answer.txt\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-digest",
   "metadata": {},
   "source": [
    "## Predict with RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unique-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "parliamentary-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_df(preds, input_texts):\n",
    "    preds_df = pd.DataFrame({\"pred\": preds.values.reshape(-1, 1).ravel()})\n",
    "    preds_df[\"input\"] = np.array([[i] * 5 for i in input_texts]).ravel()\n",
    "    preds_df[\"pred_len\"] = preds_df[\"pred\"].apply(lambda x: len(get_word_tokens(x)))\n",
    "    preds_df[\"input_len\"] = preds_df[\"input\"].apply(lambda x: len(get_word_tokens(x)))\n",
    "    preds_df[\"cosine_sim\"] = preds_df.apply(lambda x: get_similarities(model, tokenizer, x[\"pred\"], x[\"input\"]),\n",
    "                                        axis=1)\n",
    "    preds_df[\"cosine_sim\"] = preds_df[\"cosine_sim\"].apply(lambda x: x[0][0])\n",
    "    preds_df[\"rouge_l\"] = preds_df.apply(lambda x: get_rougel(x[\"pred\"], x[\"input\"]), axis=1)\n",
    "    return preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abroad-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rf_from_dev(dev_df, preds_dev, max_depth=None):\n",
    "    preds_df = preds_dev.copy()\n",
    "    dev_df_grouped = dev_df.groupby(\"input\").agg(\n",
    "        {\"output\": list, \"cosine_sim\": list, \"rouge_l\": list, \"input_len\": max, \"output_len\": list}\n",
    "    ).reset_index()\n",
    "    preds_df[\"ref\"] = [l for sublist in dev_df_grouped[\"output\"].apply(lambda x: [x] * 5).tolist() for l in sublist]\n",
    "    preds_df[\"ref\"] = preds_df[\"ref\"].apply(lambda x: [[i] for i in x])\n",
    "\n",
    "    preds_df[\"pred_len\"] = preds_df[\"pred\"].apply(lambda x: len(get_word_tokens(x)))\n",
    "    preds_df[\"input_len\"] = preds_df[\"input\"].apply(lambda x: len(get_word_tokens(x)))\n",
    "\n",
    "    preds_df[\"sari\"] = preds_df.apply(\n",
    "        lambda x: corpus_sari(\n",
    "            orig_sents=[x[\"input\"]],\n",
    "            sys_sents=[x[\"pred\"]],\n",
    "            refs_sents=x[\"ref\"],\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=1000, max_depth=max_depth, n_jobs=-1, random_state=19)\n",
    "    \n",
    "    X_train = preds_df[[\"cosine_sim\", \"rouge_l\", \"input_len\", \"pred_len\"]]\n",
    "    y_train = preds_df[\"sari\"]\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    return rf, preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "superior-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH_PRIVATE = Path(\"data/hidden_test_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "operational-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEST_PATH_PRIVATE) as f:\n",
    "    test_input = [l.strip() for l in f]\n",
    "\n",
    "dev_df = pd.read_csv(DATA_DIR / \"prepared_data\" / \"dev_df_metrics.csv\")\n",
    "dev_df_grouped = dev_df.groupby(\"input\").agg(\n",
    "    {\"output\": list, \"cosine_sim\": list, \"rouge_l\": list, \"input_len\": max, \"output_len\": list}\n",
    ").reset_index()\n",
    "\n",
    "dev_input = dev_df_grouped[\"input\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deadly-living",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 45s, sys: 115 ms, total: 2min 45s\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_test = pd.read_csv(\"submissions/private_3_sim_ep3_bs8.csv\")\n",
    "pred_test = get_preds_df(pred_test, test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "czech-cream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 28s, sys: 76 ms, total: 2min 28s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds_dev = pd.read_csv(\"submissions/dev_3_sim_ep3_bs8.csv\")\n",
    "preds_dev = get_preds_df(preds_dev, dev_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "final-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf, preds_df = get_rf_from_dev(dev_df, preds_dev, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dangerous-acceptance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.8577\n",
       "                \n",
       "                    &plusmn; 0.0360\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.08%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0837\n",
       "                \n",
       "                    &plusmn; 0.0327\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0402\n",
       "                \n",
       "                    &plusmn; 0.0263\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.64%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0184\n",
       "                \n",
       "                    &plusmn; 0.0210\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator='RandomForestRegressor(max_depth=5, n_estimators=1000, n_jobs=-1,\\n                      random_state=19)', description='\\nRandom forest feature importances; values are numbers 0 <= x <= 1;\\nall values sum to 1.\\n', error=None, method='feature importances', is_regression=True, targets=None, feature_importances=FeatureImportances(importances=[FeatureWeight(feature='x1', weight=0.857675647809487, std=0.017980220890971656, value=None), FeatureWeight(feature='x0', weight=0.08367401768938264, std=0.016346934864201045, value=None), FeatureWeight(feature='x3', weight=0.040229189966958005, std=0.013155780238509579, value=None), FeatureWeight(feature='x2', weight=0.018421144534172477, std=0.010517667120505909, value=None)], remaining=0), decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explain_weights_sklearn(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mechanical-forward",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_df[\"sari_pred\"] = rf.predict(preds_df[[\"cosine_sim\", \"rouge_l\", \"input_len\", \"pred_len\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "infrared-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test[\"sari_pred\"] = rf.predict(pred_test[[\"cosine_sim\", \"rouge_l\", \"input_len\", \"pred_len\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "demographic-korean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>input</th>\n",
       "      <th>pred_len</th>\n",
       "      <th>input_len</th>\n",
       "      <th>cosine_sim</th>\n",
       "      <th>rouge_l</th>\n",
       "      <th>sari_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>На протяжении боя Гомес два раза попадал в нок...</td>\n",
       "      <td>На протяжении боя Гомес два раза побывал в нок...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.988052</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>30.152354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>Во время боя Гомес дважды попадал в нокдаун, а...</td>\n",
       "      <td>На протяжении боя Гомес два раза побывал в нок...</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>0.982828</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>35.412536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>Гомес дважды попадал в нокдаун, а также оба бо...</td>\n",
       "      <td>На протяжении боя Гомес два раза побывал в нок...</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>0.949115</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>37.100587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>Гомес дважды упал, когда ударил боксера Кличко.</td>\n",
       "      <td>На протяжении боя Гомес два раза побывал в нок...</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0.876578</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>37.105737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>На протяжении всего боя Гомес дважды был нокау...</td>\n",
       "      <td>На протяжении боя Гомес два раза побывал в нок...</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0.937171</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>37.228614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pred  \\\n",
       "2294  На протяжении боя Гомес два раза попадал в нок...   \n",
       "2292  Во время боя Гомес дважды попадал в нокдаун, а...   \n",
       "2290  Гомес дважды попадал в нокдаун, а также оба бо...   \n",
       "2293    Гомес дважды упал, когда ударил боксера Кличко.   \n",
       "2291  На протяжении всего боя Гомес дважды был нокау...   \n",
       "\n",
       "                                                  input  pred_len  input_len  \\\n",
       "2294  На протяжении боя Гомес два раза побывал в нок...        18         18   \n",
       "2292  На протяжении боя Гомес два раза побывал в нок...        17         18   \n",
       "2290  На протяжении боя Гомес два раза побывал в нок...        14         18   \n",
       "2293  На протяжении боя Гомес два раза побывал в нок...         7         18   \n",
       "2291  На протяжении боя Гомес два раза побывал в нок...         8         18   \n",
       "\n",
       "      cosine_sim   rouge_l  sari_pred  \n",
       "2294    0.988052  0.777778  30.152354  \n",
       "2292    0.982828  0.571429  35.412536  \n",
       "2290    0.949115  0.500000  37.100587  \n",
       "2293    0.876578  0.160000  37.105737  \n",
       "2291    0.937171  0.307692  37.228614  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.random.choice(1000)\n",
    "\n",
    "pred_test.sort_values([\"input\", \"sari_pred\"])[i*5:i*5+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "furnished-silicon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лейси активно начал поединок, прессингуя и зажимая Джонса у канатов ринга, но Рой умело уходил от ударов и большинство блокировал.\n",
      "Лейси начал битву с шиканом, прижав Джонса к канатам ринга. Рой успешно ушел от ударов и большинство блокировал.\n"
     ]
    }
   ],
   "source": [
    "sample = pred_test.sort_values([\"input\", \"sari_pred\"], ascending=[True, False])[[\"input\", \"pred\"]][::5].sample()\n",
    "print(sample[\"input\"].item(), sample[\"pred\"].item(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "pleased-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pred_test.sort_values([\"input\", \"sari_pred\"], ascending=[True, False])[::5]\n",
    "\n",
    "pred_dict = dict(zip(tmp[\"input\"], tmp[\"pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "right-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [pred_dict[i] for i in test_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "understood-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions).to_csv(\n",
    "    \"submissions/private_01_3_sim_ep3_bs8_rf5_est1000_max_pred_sari/answer.txt\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-mainland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-rebecca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "excited-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.sort_values([\"input\", \"sari_pred\"], ascending=[True, False])[\"pred\"][::5].to_csv(\n",
    "    \"submissions/private_01_3_sim_ep3_bs8_rf5_est1000_max_pred_sari/answer.txt\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "negative-disclosure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7       CD8 (кластер дифференцировки 8) - это белок, и...\n",
       "12      Facebook была неоднократно наказана по постано...\n",
       "17      Facebook подвергался критике за множество нару...\n",
       "22      Игрок может создавать сложные логические венти...\n",
       "28      Оскар Александрович Энгберг изготовил обручи, ...\n",
       "                              ...                        \n",
       "4650    Южнее находится зона широколиственных лесов, с...\n",
       "4656    Ядерные силовые установки решают проблему неог...\n",
       "4663    Язык - один из часто используемых признаков ра...\n",
       "4666    Япония находится у Тихоокеанского вулканическо...\n",
       "4674    Япония имеет высокий уровень жизни и является ...\n",
       "Name: pred, Length: 1126, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.sort_values([\"input\", \"sari_pred\"], ascending=[True, False])[\"pred\"][::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-brisbane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-halloween",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-smell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-vancouver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-darwin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
