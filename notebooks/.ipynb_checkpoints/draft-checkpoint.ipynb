{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "turkish-packet",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModel,\n",
    "                          AutoModelForCausalLM,\n",
    "                          Trainer,\n",
    "                          TrainingArguments,\n",
    "                          TrainerCallback,\n",
    "                          AdamW,\n",
    "                          get_linear_schedule_with_warmup)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rouge import Rouge\n",
    "torch.manual_seed(19)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-seminar",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "knowing-complement",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b16d77d3a7d4fe89f445a53cfb441f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=655.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885e0110b0a44a238d05920dc2861bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1780720.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd08dbd30b84483a565281497fffd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38a746e5ed64a29ab7882d3e7d09952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=323.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df5d1fe1049405ebeee4ed5f40be651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1707791567.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")\n",
    "model = AutoModel.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "primary-remains",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_similarities(texts):\n",
    "    #Tokenize sentences\n",
    "    encoded_input = tokenizer(texts, padding=True, truncation=True, max_length=200, return_tensors='pt')\n",
    "\n",
    "    #Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    #Perform pooling. In this case, mean pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    similarity = cosine_similarity(sentence_embeddings)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "satisfied-sodium",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_rouge(texts):\n",
    "    rouge = Rouge()\n",
    "    *predictions, input_text = texts\n",
    "    scores = []\n",
    "    for pred in predictions:\n",
    "        score = rouge.get_scores(input_text, pred)\n",
    "        scores.append(score[0][\"rouge-l\"][\"f\"])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "minimal-optimum",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"./data\")\n",
    "TEST_PATH = DATA_DIR / \"public_test_only.csv\"\n",
    "\n",
    "with open(TEST_PATH) as f:\n",
    "    test = [i.strip() for i in f]\n",
    "\n",
    "df = pd.read_csv(\"./submissions/last_ckpt_5.csv\")\n",
    "df[\"input\"] = test\n",
    "# df = df[[\"input\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\"]]\n",
    "df[\"pred_all\"] = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "latin-lecture",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "К лесостепной зоне относится большая часть Чеченской равнины и западная часть Терско-Сунженской возвышенности.\n",
      "Большая часть Чеченской равнины и западная часть Терско-Сунженской возвышенности находятся к лесостепной зоне.\n",
      "К лесостепной зоне относится большая часть Чеченской равнины и западная часть Терско-Сунженской возвышенности.\n",
      "Он охватывает большую часть Чеченской равнины и западную часть Терско-Сунженской возвышенности.\n",
      "Большая часть Чеченской равнины и западная часть Терско-Сунженской возвышенности находятся в пределах лесостепной зоны.\n",
      "К лесостепной зоне относится большая часть Чеченской равнины и западная часть Терско-Сунженской возвышенности.\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(df.index)\n",
    "print(*df.loc[i, \"pred_all\"], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "textile-damages",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9999999, 0.9512011, 1.0000001, 0.7864466, 0.9453666],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarities(df.loc[i, \"pred_all\"])[-1, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "athletic-writing",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.999999995,\n",
       " 0.5833333283333335,\n",
       " 0.999999995,\n",
       " 0.5454545404958678,\n",
       " 0.559999995008]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rouge(df.loc[i, \"pred_all\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-shaft",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "prostate-uruguay",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "historic-alexander",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./submissions/2_3_epoch_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "actual-school",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[\"pred_all\"] = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "contained-oxford",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[\"pred_shortest\"] = df[\"pred_all\"].apply(lambda x: sorted(x, key=lambda y: len(y))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "duplicate-wagner",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [Архиепископ Новосибирской епархии Тихон Стриж...\n",
       "1      [В 1951 году Советский Союз принял на вооружен...\n",
       "2      [В 1821 году члены испанской короны и Итурбиде...\n",
       "3      [Священный Синод РПЦ утвердил иеромонаха Феодо...\n",
       "4      [28 мая 1987 года самолет «Сессна-172» Skyhawk...\n",
       "                             ...                        \n",
       "995    [В физике «физическое поле» - это место, где п...\n",
       "996    [Это семейство операционных систем реального в...\n",
       "997    [Это помогло популярности бренда, который приб...\n",
       "998    [Этот термин стал очень популярным во времена ...\n",
       "999    [Японские войска были разбиты в Маньчжурии, и ...\n",
       "Name: pred_all, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"pred_all\"].apply(lambda x: sorted(x, key=lambda y: len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "athletic-tunisia",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[\"pred_shortest\"].to_csv(\"submissions/04_2_3_epoch_shortest/answer.txt\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-tracker",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-router",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"./data\")\n",
    "\n",
    "WIKI_DIR = DATA_DIR / \"WikiSimple-translated\"\n",
    "PARAPHRASER_PATH = DATA_DIR / \"ParaPhraserPlus\" / \"ParaPhraserPlus.json\"\n",
    "\n",
    "DEV_PATH = DATA_DIR / \"dev_sents.csv\"\n",
    "TEST_PATH = DATA_DIR / \"public_test_only.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-wheat",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(path, usecols=[\"target_x\", \"target_y\"]) for path in WIKI_DIR.glob(\"*\")]\n",
    "\n",
    "df = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "df.columns = [\"input\", \"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-moore",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(DATA_DIR / \"train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-fusion",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = df.sample()\n",
    "print(sample[\"target_x\"].item(), sample[\"target_y\"].item(), sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-monte",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for col in df:\n",
    "    df[f\"{col}_set\"] = df[col].apply(lambda x: set(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-copying",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = df[df[\"target_x_set\"] & df[\"target_y_set\"] == False].sample()\n",
    "print(sample[\"target_x\"].item(), sample[\"target_y\"].item(), sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-geneva",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "friendly-klein",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"./data\")\n",
    "\n",
    "TRAIN_PATH = DATA_DIR / \"prepared_data\" / \"wiki_part.csv\"\n",
    "DEV_PATH = DATA_DIR / \"dev_sents.csv\"\n",
    "TEST_PATH = DATA_DIR / \"public_test_only.csv\"\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "valid = pd.read_csv(DEV_PATH, index_col=0)\n",
    "valid.columns = [\"input\", \"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fitting-piano",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"sberbank-ai/rugpt3large_based_on_gpt2\"\n",
    "# model_name = \"sberbank-ai/rugpt3medium_based_on_gpt2\"\n",
    "model_name = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "distant-generator",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for df in [train, valid]:\n",
    "    for col in df:\n",
    "        df[f\"{col}_n_tokens\"] = df[col].apply(lambda x: len(tokenizer.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "thermal-latter",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for df in [train, valid]:\n",
    "    df[\"n_tokens\"] = df[\"input_n_tokens\"] + df[\"output_n_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "amber-charge",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"n_tokens\"].hist(bins=np.arange(0, 301, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dated-housing",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVPElEQVR4nO3df4xdZ33n8fd3HRKC3Y2dpDuybKs2rVWUErY1o5CKCo1xG5xQ1alEaSLUOKwlq21o2SUrMEXasK2QQgtNiUSDpo0bp0IxaaCKRULBNblFSI0BQ4idpCHTELBHTlxI4nagLev2u3/cx+llOuOZub/nPu+XdDXnPOc55zzfHOczZ545905kJpKkOvyXQQ9AktQ/hr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUWDP2I2BsRpyLi2Bzbbo6IjIhLy3pExO0RMRURj0bElpa+OyPiqfLa2d0yJEmLsZg7/buA7bMbI2IDcBXw7Zbmq4HN5bUbuKP0vRi4BXgdcAVwS0Ss6WTgkqSlWzD0M/MLwPNzbLoNeDfQ+u6uHcDd2fQwsDoi1gJvAg5m5vOZ+QJwkDm+kUiSeuu8dnaKiB3AdGZ+PSJaN60Djresnyht87Wf06WXXpobN25sZ4gAfO9732PlypVt7z8sRqUOsJZhNSq1jEod0FktR44c+U5m/uhc25Yc+hHxCuB3aE7tdF1E7KY5NcTY2Bgf+tCH2j7WzMwMq1at6tbQBmZU6gBrGVajUsuo1AGd1bJ169ZvzbetnTv9Hwc2AWfv8tcDX42IK4BpYENL3/WlbRqYmNXemOvgmTkJTAKMj4/nxMTEXN0WpdFo0Mn+w2JU6gBrGVajUsuo1AG9q2XJj2xm5tHM/G+ZuTEzN9KcqtmSmc8CB4AbylM8VwKnM/Mk8FngqohYU36Be1VpkyT10WIe2bwH+FvgJyPiRETsOkf3B4GngSngT4DfBMjM54HfA75cXr9b2iRJfbTg9E5mXr/A9o0tywncNE+/vcDeJY5PktRFviNXkipi6EtSRQx9SaqIoS9JFTH0JakibX0Mg7pj454HFtXvru2j8bZySYPnnb4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSILhn5E7I2IUxFxrKXtDyLi7yLi0Yj4y4hY3bLtvRExFRFPRsSbWtq3l7apiNjT9UokSQtazJ3+XcD2WW0HgVdn5muAbwDvBYiIy4DrgJ8q+/xxRKyIiBXAR4GrgcuA60tfSVIfLRj6mfkF4PlZbZ/LzDNl9WFgfVneAezPzH/NzG8CU8AV5TWVmU9n5g+A/aWvJKmPujGn/z+Az5TldcDxlm0nStt87ZKkPuroD6NHxPuAM8DHuzMciIjdwG6AsbExGo1G28eamZnpaP9eu/nyMwt3YvjrWAprGU6jUsuo1AG9q6Xt0I+IG4FfBLZlZpbmaWBDS7f1pY1ztP+QzJwEJgHGx8dzYmKi3SHSaDToZP9eu3HPA4vqd9f2lUNdx1IM+zVZCmsZPqNSB/SulramdyJiO/Bu4Jcy8/stmw4A10XEBRGxCdgMfAn4MrA5IjZFxPk0f9l7oLOhS5KWasE7/Yi4B5gALo2IE8AtNJ/WuQA4GBEAD2fmr2fmYxFxL/A4zWmfmzLz38px3gF8FlgB7M3Mx3pQjyTpHBYM/cy8fo7mO8/R/wPAB+ZofxB4cEmjkyR1le/IlaSKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFVkw9CNib0SciohjLW0XR8TBiHiqfF1T2iMibo+IqYh4NCK2tOyzs/R/KiJ29qYcSdK5LOZO/y5g+6y2PcChzNwMHCrrAFcDm8trN3AHNL9JALcArwOuAG45+41CktQ/C4Z+Zn4BeH5W8w5gX1neB1zb0n53Nj0MrI6ItcCbgIOZ+XxmvgAc5D9/I5Ek9Vi7c/pjmXmyLD8LjJXldcDxln4nStt87ZKkPjqv0wNkZkZEdmMwABGxm+bUEGNjYzQajbaPNTMz09H+vXbz5WcW1W/Y61gKaxlOo1LLqNQBvaul3dB/LiLWZubJMn1zqrRPAxta+q0vbdPAxKz2xlwHzsxJYBJgfHw8JyYm5uq2KI1Gg07277Ub9zywqH53bV851HUsxbBfk6WwluEzKnVA72ppd3rnAHD2CZydwP0t7TeUp3iuBE6XaaDPAldFxJryC9yrSpskqY8WvNOPiHto3qVfGhEnaD6Fcytwb0TsAr4FvLV0fxC4BpgCvg+8HSAzn4+I3wO+XPr9bmbO/uWwJKnHFgz9zLx+nk3b5uibwE3zHGcvsHdJo5MkdZXvyJWkihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUkY4/Wln/2cZFfnqmJPWbd/qSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFOgr9iPhfEfFYRByLiHsi4uURsSkiDkfEVER8IiLOL30vKOtTZfvGrlQgSVq0tkM/ItYBvw2MZ+argRXAdcAHgdsy8yeAF4BdZZddwAul/bbST5LUR51O75wHXBgR5wGvAE4CbwTuK9v3AdeW5R1lnbJ9W0REh+eXJC1B26GfmdPAh4Bv0wz708AR4MXMPFO6nQDWleV1wPGy75nS/5J2zy9JWrrIzPZ2jFgDfBL4VeBF4C9o3sG/v0zhEBEbgM9k5qsj4hiwPTNPlG1/D7wuM78z67i7gd0AY2Njr92/f39b4wOYmZlh1apVbe/frqPTp7t6vE0XrRhIHb0wqGvSC9YyfEalDuislq1btx7JzPG5tnXyR1R+HvhmZv4DQER8Cng9sDoizit38+uB6dJ/GtgAnCjTQRcB35190MycBCYBxsfHc2Jiou0BNhoNOtm/XTd2+Y+o3LV95UDq6IVBXZNesJbhMyp1QO9q6WRO/9vAlRHxijI3vw14HHgIeEvpsxO4vywfKOuU7Z/Pdn/MkCS1pZM5/cM0p3O+Chwtx5oE3gO8KyKmaM7Z31l2uRO4pLS/C9jTwbglSW3o6G/kZuYtwC2zmp8Grpij778Av9LJ+SRJnfEduZJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVJGO3pGr/jg6fXrRH+L2zK1v7vFoJC1n3ulLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSIdhX5ErI6I+yLi7yLiiYj42Yi4OCIORsRT5eua0jci4vaImIqIRyNiS3dKkCQtVqd3+h8B/iozXwX8d+AJYA9wKDM3A4fKOsDVwOby2g3c0eG5JUlL1HboR8RFwBuAOwEy8weZ+SKwA9hXuu0Dri3LO4C7s+lhYHVErG33/JKkpevkTn8T8A/An0XE1yLiTyNiJTCWmSdLn2eBsbK8Djjesv+J0iZJ6pPIzPZ2jBgHHgZen5mHI+IjwD8Cv5WZq1v6vZCZayLi08CtmfnF0n4IeE9mfmXWcXfTnP5hbGzstfv3729rfAAzMzOsWrWq7f3bdXT6dFePN3YhPPfPi+t7+bqLunrubhvUNekFaxk+o1IHdFbL1q1bj2Tm+FzbOvnLWSeAE5l5uKzfR3P+/rmIWJuZJ8v0zamyfRrY0LL/+tL2QzJzEpgEGB8fz4mJibYH2Gg06GT/di32r1wt1s2Xn+HDRxd3qZ5520RXz91tg7omvWAtw2dU6oDe1dL29E5mPgscj4ifLE3bgMeBA8DO0rYTuL8sHwBuKE/xXAmcbpkGkiT1Qad/I/e3gI9HxPnA08DbaX4juTcidgHfAt5a+j4IXANMAd8vfSVJfdRR6GfmI8Bc80bb5uibwE2dnE+S1BnfkStJFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkirScehHxIqI+FpEfLqsb4qIwxExFRGfiIjzS/sFZX2qbN/Y6bklSUvTjTv9dwJPtKx/ELgtM38CeAHYVdp3AS+U9ttKP0lSH3UU+hGxHngz8KdlPYA3AveVLvuAa8vyjrJO2b6t9Jck9Umnd/p/BLwb+PeyfgnwYmaeKesngHVleR1wHKBsP136S5L65Lx2d4yIXwROZeaRiJjo1oAiYjewG2BsbIxGo9H2sWZmZjrav103X35m4U5LMHbh4o85iHqXYlDXpBesZfiMSh3Qu1raDn3g9cAvRcQ1wMuB/wp8BFgdEeeVu/n1wHTpPw1sAE5ExHnARcB3Zx80MyeBSYDx8fGcmJhoe4CNRoNO9m/XjXse6Orxbr78DB8+urhL9czbJrp67m4b1DXpBWsZPqNSB/SulrandzLzvZm5PjM3AtcBn8/MtwEPAW8p3XYC95flA2Wdsv3zmZntnl+StHS9eE7/PcC7ImKK5pz9naX9TuCS0v4uYE8Pzi1JOodOpndekpkNoFGWnwaumKPPvwC/0o3zSZLa4ztyJakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUka78YXQNj417HlhUv2dufXOPRyJpGHmnL0kVaTv0I2JDRDwUEY9HxGMR8c7SfnFEHIyIp8rXNaU9IuL2iJiKiEcjYku3ipAkLU4nd/pngJsz8zLgSuCmiLgM2AMcyszNwKGyDnA1sLm8dgN3dHBuSVIb2g79zDyZmV8ty/8EPAGsA3YA+0q3fcC1ZXkHcHc2PQysjoi17Z5fkrR0XZnTj4iNwM8Ah4GxzDxZNj0LjJXldcDxlt1OlDZJUp9EZnZ2gIhVwN8AH8jMT0XEi5m5umX7C5m5JiI+DdyamV8s7YeA92TmV2YdbzfN6R/GxsZeu3///rbHNjMzw6pVq9rev11Hp0939XhjF8Jz/9zVQ3L5uou6e8BFGtQ16QVrGT6jUgd0VsvWrVuPZOb4XNs6emQzIl4GfBL4eGZ+qjQ/FxFrM/Nkmb45VdqngQ0tu68vbT8kMyeBSYDx8fGcmJhoe3yNRoNO9m/XjYt8bHKxbr78DB8+2t2na59520RXj7dYg7omvWAtw2dU6oDe1dLJ0zsB3Ak8kZl/2LLpALCzLO8E7m9pv6E8xXMlcLplGkiS1Aed3D6+Hvg14GhEPFLafge4Fbg3InYB3wLeWrY9CFwDTAHfB97ewbklSW1oO/TL3HzMs3nbHP0TuKnd80mSOuc7ciWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRbr755hG3MYu/0WsQVpsLc/c+uYej0RSP3mnL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkiriI5s6Jx/tlEZL3+/0I2J7RDwZEVMRsaff55ekmvU19CNiBfBR4GrgMuD6iLisn2OQpJr1e3rnCmAqM58GiIj9wA7g8T6PQ1222Gmgu7av7PFIJJ1Lv0N/HXC8Zf0E8Lo+j0EDdHT6NDcO+cdZdPv3E/5eRMNk6H6RGxG7gd1ldSYinuzgcJcC3+l8VIP12yNSByyPWuKDi+7a1VqWcN5eGPrrskijUgd0VsuPzbeh36E/DWxoWV9f2l6SmZPAZDdOFhFfyczxbhxrkEalDrCWYTUqtYxKHdC7Wvr99M6Xgc0RsSkizgeuAw70eQySVK2+3uln5pmIeAfwWWAFsDczH+vnGCSpZn2f08/MB4EH+3S6rkwTDYFRqQOsZViNSi2jUgf0qJbIzF4cV5I0hPzsHUmqyEiG/nL/qIeIeCYijkbEIxHxldJ2cUQcjIinytc1gx7nXCJib0SciohjLW1zjj2abi/X6dGI2DK4kf+weep4f0RMl+vySERc07LtvaWOJyPiTYMZ9dwiYkNEPBQRj0fEYxHxztK+HK/LfLUsq2sTES+PiC9FxNdLHf+3tG+KiMNlvJ8oD7wQEReU9amyfWPbJ8/MkXrR/AXx3wOvBM4Hvg5cNuhxLbGGZ4BLZ7X9PrCnLO8BPjjocc4z9jcAW4BjC40duAb4DBDAlcDhQY9/gTreD/zvOfpeVv6dXQBsKv/+Vgy6hpbxrQW2lOUfAb5Rxrwcr8t8tSyra1P+264qyy8DDpf/1vcC15X2jwG/UZZ/E/hYWb4O+ES75x7FO/2XPuohM38AnP2oh+VuB7CvLO8Drh3cUOaXmV8Anp/VPN/YdwB3Z9PDwOqIWNuXgS5gnjrmswPYn5n/mpnfBKZo/jscCpl5MjO/Wpb/CXiC5rvjl+N1ma+W+QzltSn/bWfK6svKK4E3AveV9tnX5Oy1ug/YFhHRzrlHMfTn+qiHc/2jGEYJfC4ijpR3KAOMZebJsvwsMDaYobVlvrEvx2v1jjLlsbdlim3Z1FGmBX6G5p3lsr4us2qBZXZtImJFRDwCnAIO0vwp5MXMPFO6tI71pTrK9tPAJe2cdxRDfxT8XGZuoflppDdFxBtaN2bzZ7xl+djVch47cAfw48BPAyeBDw90NEsUEauATwL/MzP/sXXbcrsuc9Sy7K5NZv5bZv40zU8muAJ4VT/OO4qhv+BHPQy7zJwuX08Bf0nzH8RzZ3/ELl9PDW6ESzbf2JfVtcrM58r/qP8O/An/MU0w9HVExMtohuTHM/NTpXlZXpe5alnO1yYzXwQeAn6W5lTa2fdPtY71pTrK9ouA77ZzvlEM/WX9UQ8RsTIifuTsMnAVcIxmDTtLt53A/YMZYVvmG/sB4IbytMiVwOmW6YahM2te+5dpXhdo1nFdecJiE7AZ+FK/xzefMvd7J/BEZv5hy6Zld13mq2W5XZuI+NGIWF2WLwR+gebvJx4C3lK6zb4mZ6/VW4DPl5/Olm7Qv8XuxYvm0wffoDlH9r5Bj2eJY38lzacNvg48dnb8NOfvDgFPAX8NXDzosc4z/nto/nj9/2jOSe6ab+w0n2D4aLlOR4HxQY9/gTr+vIzz0fI/4dqW/u8rdTwJXD3o8c+q5edoTt08CjxSXtcs0+syXy3L6toArwG+VsZ7DPg/pf2VNL8pTQF/AVxQ2l9e1qfK9le2e27fkStJFRnF6R1J0jwMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKvL/AXe8GAfxpL62AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid[\"n_tokens\"].hist(bins=np.arange(0, 301, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "another-discharge",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "relevant-bathroom",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50261, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens = {\n",
    "    \"bos_token\": \"<|startoftext|>\",\n",
    "    \"pad_token\": \"<|pad|>\",\n",
    "    \"sep_token\": \"<|sep|>\",\n",
    "}\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "tokenizer.all_special_tokens_extended\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "amino-medline",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max model length is 1000000000000000019884624838656 for this model, although the actual embedding size for GPT small is 768\n",
      "The beginning of sequence token <|startoftext|> token has the id 50258\n",
      "The end of sequence token <|endoftext|> has the id 50257\n",
      "The sep token <|sep|> has the id 50260\n",
      "The padding token <|pad|> has the id 50259\n"
     ]
    }
   ],
   "source": [
    "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
    "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
    "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
    "print(\"The sep token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.sep_token_id), tokenizer.sep_token_id))\n",
    "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-yeast",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "incomplete-parallel",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SimplificationDataset(Dataset):\n",
    "    def __init__(self, texts_list, tokenizer, gpt2_type=\"gpt2\", max_length=1024):\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        texts_combined = []\n",
    "        for input_text, out_text in texts_list:\n",
    "            text_combined = f\"<|startoftext|>{input_text}<|sep|>{out_text}<|endoftext|>\"\n",
    "            texts_combined.append(text_combined)\n",
    "        self.encodings = tokenizer(texts_combined,\n",
    "                              truncation=True,\n",
    "                              max_length=max_length,\n",
    "                              padding=\"max_length\",\n",
    "                              return_tensors=\"pt\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = item[\"input_ids\"]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "therapeutic-opera",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_cols = [\"input\", \"output\"]\n",
    "train_dataset = SimplificationDataset(train[data_cols].values.tolist(), tokenizer, max_length=MAX_LENGTH)\n",
    "valid_dataset = SimplificationDataset(valid[data_cols].values.tolist(), tokenizer, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "funded-antarctica",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10897"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset) // 8 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "retained-ferry",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_random_example(dataset):\n",
    "    sample = dataset.sample()\n",
    "    prompt = f'<|startoftext|>{sample[\"input\"].item()}<|sep|>'\n",
    "    true_output = sample[\"output\"].item()\n",
    "    return prompt, true_output\n",
    "\n",
    "\n",
    "class PrintExampleCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        prompt, true_output = get_random_example(valid)\n",
    "        print(prompt.strip(\"<|startoftext|>\").strip(\"<|sep|>\"), true_output, sep=\"\\n\")\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        sample_outputs = model.generate(\n",
    "                                input_ids,\n",
    "                                do_sample=True,   \n",
    "                                top_k=50, \n",
    "                                max_length = MAX_LENGTH,\n",
    "                                top_p=0.95,\n",
    "                                temperature=0.9,\n",
    "                                num_return_sequences=1\n",
    "                            ).detach().cpu()\n",
    "\n",
    "        for sample in sample_outputs:\n",
    "            res = tokenizer.decode(sample, skip_special_tokens=False).split(\"<|sep|>\")[1].replace(\"<|pad|>\", \"\").replace(\"<|endoftext|>\", \"\")\n",
    "            print(res)\n",
    "\n",
    "            \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    run_name=\"asdf\",\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_first_step=True,\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_steps=500,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    weight_decay=0,\n",
    "    fp16=True,\n",
    "    seed=19,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    callbacks=[PrintExampleCallback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sorted-beads",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100500 / 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "optical-federal",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_n_gpu': 1,\n",
      " 'adafactor': False,\n",
      " 'adam_beta1': 0.9,\n",
      " 'adam_beta2': 0.999,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'dataloader_drop_last': False,\n",
      " 'dataloader_num_workers': 0,\n",
      " 'dataloader_pin_memory': True,\n",
      " 'ddp_find_unused_parameters': None,\n",
      " 'debug': False,\n",
      " 'deepspeed': None,\n",
      " 'disable_tqdm': False,\n",
      " 'do_eval': None,\n",
      " 'do_predict': False,\n",
      " 'do_train': False,\n",
      " 'eval_accumulation_steps': None,\n",
      " 'eval_steps': 50,\n",
      " 'evaluation_strategy': 'steps',\n",
      " 'fp16': True,\n",
      " 'fp16_backend': 'auto',\n",
      " 'fp16_opt_level': 'O1',\n",
      " 'gradient_accumulation_steps': 1,\n",
      " 'greater_is_better': None,\n",
      " 'group_by_length': False,\n",
      " 'ignore_data_skip': False,\n",
      " 'label_names': None,\n",
      " 'label_smoothing_factor': 0.0,\n",
      " 'learning_rate': 5e-05,\n",
      " 'load_best_model_at_end': False,\n",
      " 'local_rank': -1,\n",
      " 'logging_dir': './logs',\n",
      " 'logging_first_step': True,\n",
      " 'logging_steps': 100,\n",
      " 'lr_scheduler_type': 'linear',\n",
      " 'max_grad_norm': 1.0,\n",
      " 'max_steps': -1,\n",
      " 'metric_for_best_model': None,\n",
      " 'no_cuda': False,\n",
      " 'num_train_epochs': 5,\n",
      " 'output_dir': './results',\n",
      " 'overwrite_output_dir': False,\n",
      " 'past_index': -1,\n",
      " 'per_device_eval_batch_size': 8,\n",
      " 'per_device_train_batch_size': 8,\n",
      " 'per_gpu_eval_batch_size': None,\n",
      " 'per_gpu_train_batch_size': None,\n",
      " 'prediction_loss_only': False,\n",
      " 'remove_unused_columns': True,\n",
      " 'report_to': ['tensorboard'],\n",
      " 'run_name': 'asdf',\n",
      " 'save_steps': 500,\n",
      " 'save_total_limit': None,\n",
      " 'seed': 19,\n",
      " 'sharded_ddp': False,\n",
      " 'tpu_metrics_debug': False,\n",
      " 'tpu_num_cores': None,\n",
      " 'warmup_steps': 500,\n",
      " 'weight_decay': 0}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(training_args.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "compatible-breast",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-d5e2d4830c60>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='81' max='108980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    81/108980 01:00 < 22:59:48, 1.32 it/s, Epoch 0.00/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.082700</td>\n",
       "      <td>0.827583</td>\n",
       "      <td>34.663600</td>\n",
       "      <td>98.259000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В результате успешных действий русской разведки командованию русской армии было детально известно состояние Великой армии.\n",
      "Русская разведка дала командованию все сведения о противнике.\n",
      "Во время войны разведывательная группа имела подробное описание состояния Великой армии и армий, а также подробное описание ее планов и планов.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гениальнейшим поэтом Польши и одновременно одним из великих мировых поэтов является Адам Мицкевич, признанный вождь польского романтизма.\n",
      "Адам Мицкевич  - это гениальный поэт Польши и великий  поэт во всем мире. Он возглавил жанр романтизма в Польше.\n",
      "Гениальным поэтом Польши и одновременно одним из величайших мировыми лидерами является Адам Мицкевич.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_amp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_apex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "subsequent-combat",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prompt, true_output = get_random_example(valid)\n",
    "print(prompt, true_output, sep=\"\\n\\n\")\n",
    "print(\"\\n\")\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "sample_outputs = model.generate(\n",
    "                        input_ids,\n",
    "                        do_sample=True,   \n",
    "                        top_k=50, \n",
    "                        max_length = MAX_LENGTH,\n",
    "                        top_p=0.95,\n",
    "                        temperature=0.5,\n",
    "                        num_return_sequences=5\n",
    "                    ).detach().cpu()\n",
    "\n",
    "for sample in sample_outputs:\n",
    "    res = tokenizer.decode(sample, skip_special_tokens=False).split(\"<|sep|>\")[1].replace(\"<|pad|>\", \"\").replace(\"<|endoftext|>\", \"\")\n",
    "    print(res, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-reconstruction",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-public",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-revolution",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SimplificationDataset(Dataset):\n",
    "    def __init__(self, texts_list, tokenizer, gpt2_type=\"gpt2\", max_length=1024):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "\n",
    "        for input_text, out_text in texts_list:\n",
    "            text_combined = f\"<|startoftext|>{input_text}<|sep|>{out_text}<|endoftext|>\"\n",
    "            encodings_dict = tokenizer(text_combined,\n",
    "                                       truncation=True,\n",
    "                                       max_length=max_length,\n",
    "                                       padding=\"max_length\",\n",
    "                                       return_tensors=\"pt\")\n",
    "            self.input_ids.append(encodings_dict['input_ids'])\n",
    "            self.attn_masks.append(encodings_dict['attention_mask'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-embassy",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_cols = [\"input\", \"output\"]\n",
    "train_dataset = SimplificationDataset(train.loc[:5000, data_cols].values.tolist(), tokenizer, max_length=MAX_LENGTH)\n",
    "valid_dataset = SimplificationDataset(valid[data_cols].values.tolist(), tokenizer, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-caribbean",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-photographer",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create the DataLoaders for our training and validation datasets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,  # The training samples.\n",
    "    sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "    batch_size = TRAIN_BATCH_SIZE # Trains with this batch size.\n",
    ")\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "    valid_dataset, # The validation samples.\n",
    "    sampler = SequentialSampler(valid_dataset), # Pull out batches sequentially.\n",
    "    batch_size = VALID_BATCH_SIZE # Evaluate with this batch size.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-scale",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-biotechnology",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 19\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-precipitation",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# some parameters I cooked up that work reasonably well\n",
    "\n",
    "epochs = 5\n",
    "learning_rate = 5e-5\n",
    "warmup_steps = 1e2\n",
    "epsilon = 1e-8\n",
    "\n",
    "# this produces sample output every 100 steps\n",
    "sample_every = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-former",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate,\n",
    "                  eps = epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-raleigh",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "print(\"total steps:\", total_steps)\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "# This changes the learning rate as the training loop progresses\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = warmup_steps, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-fisher",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-guard",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-rover",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_random_example(dataset):\n",
    "    sample = dataset.sample()\n",
    "    prompt = f'<|startoftext|>{sample[\"input\"].item()}<|sep|>'\n",
    "    true_output = sample[\"output\"].item()\n",
    "    return prompt, true_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-diagram",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_t0 = time.time()\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(  b_input_ids,\n",
    "                          labels=b_labels, \n",
    "                          attention_mask = b_masks,\n",
    "                          token_type_ids=None\n",
    "                        )\n",
    "\n",
    "        loss = outputs[0]  \n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "\n",
    "        # Get sample every x batches.\n",
    "        if step % sample_every == 0 and not step == 0:\n",
    "\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
    "\n",
    "            model.eval()\n",
    "            prompt, true_output = get_random_example(valid)\n",
    "            print(prompt, true_output, sep=\"\\n\")\n",
    "            input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "            sample_outputs = model.generate(\n",
    "                                    input_ids,\n",
    "                                    do_sample=True,   \n",
    "                                    top_k=50, \n",
    "                                    max_length = MAX_LENGTH,\n",
    "                                    top_p=0.95, \n",
    "                                    num_return_sequences=1\n",
    "                                )\n",
    "            del input_ids\n",
    "            for i, sample_output in enumerate(sample_outputs):\n",
    "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=False)))\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            outputs  = model(b_input_ids, \n",
    "#                            token_type_ids=None, \n",
    "                             attention_mask = b_masks,\n",
    "                            labels=b_labels)\n",
    "          \n",
    "            loss = outputs[0]  \n",
    "            \n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss        \n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    validation_time = format_time(time.time() - t0)    \n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-australia",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-injection",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "tropical-extreme",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tender-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"./data\")\n",
    "\n",
    "TRAIN_PATH = DATA_DIR / \"prepared_data\" / \"wiki_part.csv\"\n",
    "DEV_PATH = DATA_DIR / \"dev_sents.csv\"\n",
    "TEST_PATH = DATA_DIR / \"public_test_only.csv\"\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "valid = pd.read_csv(DEV_PATH, index_col=0)\n",
    "valid.columns = [\"input\", \"output\"]\n",
    "\n",
    "with open(TEST_PATH) as f:\n",
    "    test = pd.DataFrame({\"input\": [line.strip() for line in f]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "grateful-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_example(dataset):\n",
    "    sample = dataset.sample()\n",
    "    prompt = f'<|startoftext|>{sample[\"input\"].item()}<|sep|>'\n",
    "    true_output = sample[\"output\"].item()\n",
    "    return prompt, true_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-little",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "# model_name = \"sberbank-ai/rugpt3large_based_on_gpt2\"\n",
    "# model_name = \"sberbank-ai/rugpt3medium_based_on_gpt2\"\n",
    "model_path = \"result_rugpt3medium_sim_comb/checkpoint-207264/\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3medium_based_on_gpt2\")\n",
    "special_tokens = {\n",
    "    \"bos_token\": \"<|startoftext|>\",\n",
    "    \"pad_token\": \"<|pad|>\",\n",
    "    \"sep_token\": \"<|sep|>\",\n",
    "}\n",
    "tokenizer.add_special_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_df(preds, input_texts):\n",
    "    preds_df = pd.DataFrame({\"pred\": preds.values.reshape(-1, 1).ravel()})\n",
    "    preds_df[\"input\"] = np.array([[i] * 5 for i in input_texts]).ravel()\n",
    "    preds_df[\"pred_len\"] = preds_df[\"pred\"].apply(lambda x: len(get_word_tokens(x)))\n",
    "    preds_df[\"input_len\"] = preds_df[\"pred\"].apply(lambda x: len(get_word_tokens(x)))\n",
    "    preds_df[\"cosine_sim\"] = preds_df.apply(lambda x: get_similarities(model, tokenizer, x[\"pred\"], x[\"input\"]),\n",
    "                                        axis=1)\n",
    "    preds_df[\"cosine_sim\"] = preds_df[\"cosine_sim\"].apply(lambda x: x[0][0])\n",
    "    preds_df[\"rouge_l\"] = preds_df.apply(lambda x: get_rougel(x[\"pred\"], x[\"input\"]), axis=1)\n",
    "    return preds_df\n",
    "\n",
    "def get_rf_from_dev(dev_df, preds_dev):\n",
    "    preds_df = preds_dev.copy()\n",
    "    dev_df_grouped = dev_df.groupby(\"input\").agg(\n",
    "        {\"output\": list, \"cosine_sim\": list, \"rouge_l\": list, \"input_len\": max, \"output_len\": list}\n",
    "    ).reset_index()\n",
    "    preds_df[\"ref\"] = [l for sublist in dev_df_grouped[\"output\"].apply(lambda x: [x] * 5).tolist() for l in sublist]\n",
    "    preds_df[\"ref\"] = preds_df[\"ref\"].apply(lambda x: [[i] for i in x])\n",
    "\n",
    "    preds_df[\"pred_len\"] = preds_df[\"pred\"].apply(lambda x: len(get_word_tokens(x)))\n",
    "    preds_df[\"input_len\"] = preds_df[\"input\"].apply(lambda x: len(get_word_tokens(x)))\n",
    "\n",
    "    preds_df[\"sari\"] = preds_df.apply(\n",
    "        lambda x: corpus_sari(\n",
    "            orig_sents=[x[\"input\"]],\n",
    "            sys_sents=[x[\"pred\"]],\n",
    "            refs_sents=x[\"ref\"],\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    rf = RandomForestRegressor(n_jobs=-1, random_state=19)\n",
    "    \n",
    "    X_train = preds_df[[\"cosine_sim\", \"rouge_l\", \"input_len\", \"pred_len\"]]\n",
    "    y_train = preds_df[\"sari\"]\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    return rf, preds_df\n",
    "\n",
    "dev_input = dev_df_grouped[\"input\"].tolist()\n",
    "dev_df = pd.read_csv(DATA_DIR / \"prepared_data\" / \"dev_df_metrics.csv\")\n",
    "\n",
    "rf, preds_df = get_rf_from_dev(dev_df, preds_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sensitive-skirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пограничная охрана Финляндии входит в подчинение министерства внутренних дел, но может быть включена в вооружённые силы в случае необходимости.\n",
      "--------------------------------------------------------------------------------\n",
      "Пограничники Финляндии подчиняются министерству внутренних дел, но могут присоединиться к вооружённым силам,если будет нужно.\n",
      "\n",
      "\n",
      "\n",
      "Пограничная охрана Финляндии входит в подчинение министерства внутренних дел, но может быть включена в вооруженные силы при необходимости. \n",
      "\n",
      "Финская пограничная служба входит в подчинение правительства. \n",
      "\n",
      "Пограничная охрана Финляндии входит в состав Министерства внутренних дел, но может быть включена в вооруженные силы, если необходимости. \n",
      "\n",
      "Пограничная охрана Финляндии входит в состав министерства внутренних дел, но может быть добавлена в вооруженные силы в случае необходимости. \n",
      "\n",
      "Финская пограничная охрана - это пограничная охрана, контролирующая границу. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 200\n",
    "prompt, true_output = get_random_example(valid)\n",
    "# prompt = \"\"\"\n",
    "# Высокопоставленный чиновник в администрации Байдена сообщил телеканалу, что американские власти пытались связаться с Северной Кореей \"по нескольким каналам, начиная с середины февраля, в том числе в Нью-Йорке\", через миссию в ООН.\n",
    "\n",
    "# \"\"\".strip()\n",
    "# true_output = \"\"\n",
    "print(prompt.replace(\"<|startoftext|>\", \"\").replace(\"<|sep|>\", \"\"), true_output, sep=\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "print(\"\\n\")\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "sample_outputs = model.generate(\n",
    "                        input_ids,\n",
    "                        do_sample=True,   \n",
    "                        top_k=50, \n",
    "                        max_length = MAX_LENGTH,\n",
    "                        top_p=0.95,\n",
    "                        temperature=0.9,\n",
    "                        length_penalty=0.7,\n",
    "                        num_return_sequences=5,\n",
    "                    ).detach().cpu()\n",
    "\n",
    "for sample in sample_outputs:\n",
    "    res = tokenizer.decode(sample, skip_special_tokens=False).split(\"<|sep|>\")[1].replace(\"<|pad|>\", \"\").replace(\"<|endoftext|>\", \"\")\n",
    "    print(res, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-iceland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "educated-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_prediction(text):\n",
    "    prompt = f\"<|startoftext|>{text}<|sep|>\"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    sample_outputs = model.generate(\n",
    "        input_ids,\n",
    "        do_sample=True,   \n",
    "        top_k=50, \n",
    "        max_length = MAX_LENGTH,\n",
    "        top_p=0.95,\n",
    "        temperature=0.9,\n",
    "        length_penalty=0.7,\n",
    "        num_return_sequences=5,\n",
    "    ).detach().cpu()\n",
    "\n",
    "    predictions = []\n",
    "    for sample in sample_outputs:\n",
    "        result = (tokenizer.decode(sample, skip_special_tokens=False)\n",
    "                        .split(\"<|sep|>\")[1]\n",
    "                        .replace(\"<|pad|>\", \"\")\n",
    "                        .replace(\"<|endoftext|>\", \"\"))\n",
    "        predictions.append(result)\n",
    "    prediction = sorted(predictions, key=lambda x: len(x))[0]\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "religious-marijuana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['14 апреля 2003 году архиепископом Новосибирским и Бердским Тихоном пострижен в монашество с наречением имени Феодор в честь праведного Феодора Томского.'],\n",
       "       ['22 марта 1951 года боевая машина БМ-24 постановлением Совета Министров СССР №875-441сс была принята на вооружение Советской армии.'],\n",
       "       ['24 августа 1821 года представители испанской короны и Итурбиде подписали Кордовский договор, в котором признавалась независимость Мексики в соответствии с положениями «Плана Игуала».'],\n",
       "       ['26 декабря 2013 года решением Священного Синода Русской Православной Церкви иеромонах Феодор был официально утверждён в должности наместника Камчатского Пантелеимонова монастыря.']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "greatest-announcement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  1  2\n",
       "1  3  4"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"pred\": [[1, 2], [3, 4]]})[\"pred\"].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "personal-investing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|>14 апреля 2003 году архиепископом Новосибирским и Бердским Тихоном пострижен в монашество с наречением имени Феодор в честь праведного Феодора Томского.<|sep|>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "14 апреля 2003 года архиепископом Новосибирским и Бердским Тихоном пострижен в монашество с наречением имени Феодор в честь Феодора Томского. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "MAX_LENGTH = 200\n",
    "\n",
    "# text = \"В других странах, таких как Ирландия, Уэльс, Ирландия, Канада и Австралия, термин «концерт» обычно означает только органные произведения, но не оперы.\"\n",
    "text = test[\"input\"].sample().item()\n",
    "text = test[\"input\"][0]\n",
    "\n",
    "prompt, true_output = \"<|startoftext|>\" + text + \"<|sep|>\", \"\"\n",
    "# prompt, true_output = text, \"\"\n",
    "\n",
    "print(prompt, true_output, sep=\"\\n\\n\")\n",
    "print(\"\\n\")\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "sample_outputs = model.generate(\n",
    "                        input_ids,\n",
    "                        do_sample=True,   \n",
    "                        top_k=50, \n",
    "                        max_length = MAX_LENGTH,\n",
    "                        top_p=0.95,\n",
    "                        temperature=0.9,\n",
    "                        length_penalty=0.7,\n",
    "                        num_return_sequences=1\n",
    "                    ).detach().cpu()\n",
    "\n",
    "for sample in sample_outputs:\n",
    "    res = tokenizer.decode(sample, skip_special_tokens=False).split(\"<|sep|>\")[1].replace(\"<|pad|>\", \"\").replace(\"<|endoftext|>\", \"\")\n",
    "    print(res, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "religious-trial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.211329422942415"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(0.7935938835144043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "taken-kitchen",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'easse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-bc62e13580a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0measse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'easse'"
     ]
    }
   ],
   "source": [
    "import easse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-spanish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-victory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-aruba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
